{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor()]\n",
    ")\n",
    "\n",
    "train_dataset = datasets.FashionMNIST(root=\"./data\", train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.FashionMNIST(root=\"./data\", train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NN,self).__init__()\n",
    "        self.layer1 = nn.Linear(28*28, 128) # Input-Layer (28x28) -> Hidden Layer 128\n",
    "        self.layer2 = nn.Linear(128, 64)\n",
    "        self.dropout = nn.Dropout(0.2) # Vermeidung vom Overfitting\n",
    "        self.layer3 = nn.Linear(64,10) # Output -> Wahrscheinlichkeiten für Produktkategorien\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = x.view(-1, 28*28) # (2D -> 1D), Flatten der Eingabe\n",
    "        x = torch.relu(self.layer1(x))\n",
    "        x = torch.relu(self.layer2(x))\n",
    "        x = self.dropout(x) # Dropout anwenden\n",
    "        x = self.layer3(x) # Output-Layer\n",
    "        return x \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss:564.7575409263372\n",
      "Epoch [2/20], Loss:385.0481908470392\n",
      "Epoch [3/20], Loss:347.2964168712497\n",
      "Epoch [4/20], Loss:321.6767787337303\n",
      "Epoch [5/20], Loss:305.29730136692524\n",
      "Epoch [6/20], Loss:290.8224961683154\n",
      "Epoch [7/20], Loss:276.81886015087366\n",
      "Epoch [8/20], Loss:266.6976313665509\n",
      "Epoch [9/20], Loss:258.8212715908885\n",
      "Epoch [10/20], Loss:250.42174124717712\n",
      "Epoch [11/20], Loss:242.5419107005\n",
      "Epoch [12/20], Loss:235.29350101202726\n",
      "Epoch [13/20], Loss:229.10020893067122\n",
      "Epoch [14/20], Loss:223.53712476044893\n",
      "Epoch [15/20], Loss:220.13756193593144\n",
      "Epoch [16/20], Loss:212.74210831150413\n",
      "Epoch [17/20], Loss:206.97866959869862\n",
      "Epoch [18/20], Loss:203.1010755673051\n",
      "Epoch [19/20], Loss:196.5588060952723\n",
      "Epoch [20/20], Loss:193.94845896586776\n"
     ]
    }
   ],
   "source": [
    "model = NN()\n",
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.001)   # moderne Variante von SGD\n",
    "\n",
    "num_epochs = 20 # 20 mal werden wir die Daten unserem Algorithmus zeigen\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images,labels in train_loader: # Samplen aus Trainingsdaten \n",
    "        optimizer.zero_grad() # Gradienten zurücksetzen\n",
    "        outputs = model(images) \n",
    "        curr_loss = loss(outputs, labels)\n",
    "\n",
    "        curr_loss.backward() # Ableitung\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += curr_loss.item()\n",
    "    \n",
    "    print(\"Epoch [\" + str(epoch+1) + \"/\" + str(num_epochs) + \"], Loss:\" + str(running_loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genauigkeit: 0.8905\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        outputs = model(images)\n",
    "        predicted = torch.max(outputs.data,1)[-1] # argmax von outputs = die Kategorie mit der maximalen Wahrscheinlichkeit\n",
    "        total += labels.size(0) # Gesamtanzahl\n",
    "        correct += (predicted==labels).sum().item() # Anzahl der korrekt klassifizierten Labels\n",
    "\n",
    "accuracy = correct/total\n",
    "print(\"Genauigkeit: \" + str(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
